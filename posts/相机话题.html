<!DOCTYPE html><html><head>
      <title>相机话题介绍</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:///c:\Users\LingJiaXiaoHu\.vscode\extensions\shd101wyy.markdown-preview-enhanced-0.8.20\crossnote\dependencies\katex\katex.min.css">
      
      
      
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<h2 id="相机话题介绍">相机话题介绍 </h2>
<p>除了激光雷达，机器人还可以通过相机来感知这个世界，这就是机器人的机器视觉。</p>
<p>机器人使用的相机有很多种类型，最常见的是普通的彩色相机，和具有立体感知能力的RGB-D深度相机，借助机器视觉，机器人可以实现物体识别和定位、3D环境建模、以及最近特别热门的多模态具身智能，那么相机在ROS中应该如何使用呢？是不是也像激光雷达和IMU一样，直接通过订阅话题就能获取数据呢，确实如此，但是相机话题特别多。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730363298173-7a43126f-489b-498c-9a3f-a53414bbad10.png" alt=""></p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>ht@ht-VirtualBox:~$ rostopic list
/amcl/parameter_descriptions
/amcl/parameter_updates
/amcl_pose
/chargers_marker
/clicked_point
/clock
/cmd_vel
/diagnostics
/gazebo/link_states
/gazebo/model_states
/gazebo/parameter_descriptions
/gazebo/parameter_updates
/gazebo/performance_metrics
/gazebo/set_link_state
/gazebo/set_model_state
/imu/data
/initialpose
/joint_states
/kinect2/hd/camera_info
/kinect2/hd/image_color_rect
/kinect2/hd/image_color_rect/compressed
/kinect2/hd/image_color_rect/compressed/parameter_descriptions
/kinect2/hd/image_color_rect/compressed/parameter_updates
/kinect2/hd/image_color_rect/compressedDepth
/kinect2/hd/image_color_rect/compressedDepth/parameter_descriptions
/kinect2/hd/image_color_rect/compressedDepth/parameter_updates
/kinect2/hd/image_color_rect/theora
/kinect2/hd/image_color_rect/theora/parameter_descriptions
/kinect2/hd/image_color_rect/theora/parameter_updates
/kinect2/hd/parameter_descriptions
/kinect2/hd/parameter_updates
/kinect2/qhd/camera_info
/kinect2/qhd/image_color_rect
/kinect2/qhd/image_color_rect/compressed
/kinect2/qhd/image_color_rect/compressed/parameter_descriptions
/kinect2/qhd/image_color_rect/compressed/parameter_updates
/kinect2/qhd/image_color_rect/compressedDepth
/kinect2/qhd/image_color_rect/compressedDepth/parameter_descriptions
/kinect2/qhd/image_color_rect/compressedDepth/parameter_updates
/kinect2/qhd/image_color_rect/theora
/kinect2/qhd/image_color_rect/theora/parameter_descriptions
/kinect2/qhd/image_color_rect/theora/parameter_updates
/kinect2/qhd/parameter_descriptions
/kinect2/qhd/parameter_updates
/kinect2/qhd/points
/kinect2/sd/depth/camera_info
/kinect2/sd/depth_camera_info
/kinect2/sd/image_depth_rect
/kinect2/sd/image_ir_rect
/kinect2/sd/image_ir_rect/compressed
/kinect2/sd/image_ir_rect/compressed/parameter_descriptions
/kinect2/sd/image_ir_rect/compressed/parameter_updates
/kinect2/sd/image_ir_rect/compressedDepth
/kinect2/sd/image_ir_rect/compressedDepth/parameter_descriptions
/kinect2/sd/image_ir_rect/compressedDepth/parameter_updates
/kinect2/sd/image_ir_rect/theora
/kinect2/sd/image_ir_rect/theora/parameter_descriptions
/kinect2/sd/image_ir_rect/theora/parameter_updates
/kinect2/sd/parameter_descriptions
/kinect2/sd/parameter_updates
/kinect2/sd/points
/map
/map_metadata
/map_updates
/move_base/GlobalPlanner/parameter_descriptions
/move_base/GlobalPlanner/parameter_updates
/move_base/GlobalPlanner/plan
/move_base/GlobalPlanner/potential
/move_base/TebLocalPlannerROS/global_plan
/move_base/TebLocalPlannerROS/local_plan
/move_base/TebLocalPlannerROS/obstacles
/move_base/TebLocalPlannerROS/parameter_descriptions
/move_base/TebLocalPlannerROS/parameter_updates
/move_base/TebLocalPlannerROS/teb_feedback
/move_base/TebLocalPlannerROS/teb_markers
/move_base/TebLocalPlannerROS/teb_poses
/move_base/TebLocalPlannerROS/via_points
/move_base/cancel
/move_base/current_goal
/move_base/feedback
/move_base/global_costmap/costmap
/move_base/global_costmap/costmap_updates
/move_base/global_costmap/footprint
/move_base/global_costmap/inflation_layer/parameter_descriptions
/move_base/global_costmap/inflation_layer/parameter_updates
/move_base/global_costmap/obstacle_layer/parameter_descriptions
/move_base/global_costmap/obstacle_layer/parameter_updates
/move_base/global_costmap/parameter_descriptions
/move_base/global_costmap/parameter_updates
/move_base/global_costmap/static_layer/parameter_descriptions
/move_base/global_costmap/static_layer/parameter_updates
/move_base/goal
/move_base/local_costmap/costmap
/move_base/local_costmap/costmap_updates
/move_base/local_costmap/footprint
/move_base/local_costmap/inflation_layer/parameter_descriptions
/move_base/local_costmap/inflation_layer/parameter_updates
/move_base/local_costmap/obstacle_layer/parameter_descriptions
/move_base/local_costmap/obstacle_layer/parameter_updates
/move_base/local_costmap/parameter_descriptions
/move_base/local_costmap/parameter_updates
/move_base/parameter_descriptions
/move_base/parameter_updates
/move_base/recovery_status
/move_base/result
/move_base/status
/move_base_simple/goal
/odom
/particlecloud
/rosout
/rosout_agg
/scan
/scan_filtered
/tf
/tf_static
/visualization_marker
/visualization_marker_array
/waterplus/add_charger
/waterplus/add_waypoint
/waterplus/navi_result
/waterplus/navi_waypoint
/waypoints_marker
/waypoints_marker_array
ht@ht-VirtualBox:~$ 
</code></pre><p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730363529543-994b3ae6-e237-4a8d-9dc6-c4092b1a9630.png" alt=""></p>
<p>最常用的彩色图像话题：</p>
<p>彩色图像经常会在三个话题中发布，</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730365672048-38dcba96-08e0-4f73-a9c2-c937f7aa1198.png" alt=""></p>
<p>首先是/image_raw话题，这个话题是相机的原始数据，<img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730365755642-e580ec84-df5a-4981-8588-cdb7e7ca1c22.png" alt=""></p>
<p>什么是原始数据？相机硬件在发展的过程中，为了降低成本，相机的感光芯片一次只能检测每个像素的光强，也就是它的原始输出（黑白图像），后来一维名叫Bryce Bayer的工程师发明了一种方法，在感光芯片上，覆盖上一层红绿蓝RGB栅格滤镜，</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730366103410-d6f367d2-7590-43df-8fc3-1a44a5a61190.png" alt=""></p>
<p>光线透过滤镜后，感光芯片上的每个像素就只能感知其中一种颜色的强度，于是黑白图像变成下面这样的图像，也叫做Bayer阵列图像，</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730366266913-8373a0df-f170-4f3d-8431-4e79185acee0.png" alt=""></p>
<p>这就是/image_raw话题里的原始数据。</p>
<p>这个Bayer阵列和咱们看到的彩色图像不一样啊？</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730366468196-033db494-b623-4d10-9e3f-d94726946e52.png" alt=""></p>
<p>彩色图像里的每个像素都是有红绿蓝（RGB）三种颜色组成，这个原始数据里每个像素只有一种颜色，那另外两种颜色上哪里找去？咱们虽然没有直接检测另外两种颜色，但每个像素周围总有一个像素检测到了咱们缺失的颜色之一，所有可以通过插值的方法猜出咱们的这个像素所缺失的两种颜色的大概数值，通过这种跟邻居借颜色的方法，就可以将原始的Bayer阵列图像里每个像素缺失的另外两个颜色数值都补齐了，这样就能得到咱们正常看到的彩色图像。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730366774207-9e05bb24-8f58-483c-b643-ce23bcdf3d9a.png" alt=""></p>
<p>这个彩色图像的数据一般会发布在话题/image_color中，</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730367130562-2fac93e1-231d-494f-96c7-b83675cdf9e4.png" alt=""></p>
<p>除了上述两个话题，还有一个叫做/image_color_rect的话题也输出彩色图像，rect是rectify的缩写，也就是相机的畸变矫正，比如咱们平时给女朋友拍照的时候，都知道把女朋友的腿放在图像边缘的位置，这样她的双腿就会被拉长，这样就得到一个大长腿的女朋友，这就是相机镜头的畸变现象。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730367296339-29d61d2a-14e7-41c3-964e-fd956be4254f.png" alt=""></p>
<p>在机器人的视觉图像里，也存在类似的畸变，这就要进行recitfy畸变矫正以获得一个正常比例的图像，这样能够显著提高目标识别的成功率，在视觉slam中这个矫正操作更为重要，会直接影响特征点的匹配效果。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730367500992-ceaeb0d6-9cb6-4a7f-96d3-68a3b325b870.png" alt=""><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730367531889-c0abe077-de2a-4611-84e8-31c1d861a41d.png" alt=""></p>
<p>如果咱们像进行畸变校正，还可以通过订阅/camera_info话题，获取相机的参数，自行进行畸变矫正。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730367776120-25223491-1699-4147-b10a-77dd294c366e.png" alt=""></p>
<p>/image_color_rect这个话题中的图像消息包的发布频率与相机帧率有关，常见的多是30fps的倍数，</p>
<p>可以使用rostopic查看</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730368391819-48c18870-3c6b-494d-bb53-cacf65327037.png" alt=""></p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>ht@ht-VirtualBox:~$ rostopic hz /kinect2/qhd/image_color_rect
WARNING: topic [/kinect2/qhd/image_color_rect] does not appear to be published yet

</code></pre><p>另外这个话题的消息格式是sensor_msgs/Image类型，在ROS Index网站中可以查看该消息类型的数据格式，</p>
<p>但是咱们一般使用的时候都会将其转换成Opencv的Mat类型，使用Opencv的函数进行图像处理，所有图像数据在ROS中的消息格式可以不用具体了解，只要知道转换方法就行了。</p>
<h2 id="ros-相机图像获取的-c-实现">ROS 相机图像获取的 C++ 实现 </h2>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730452356700-d2962ce8-33cb-4285-a0ca-f397222b10b3.png" alt=""></p>
<p>首先订阅机器人头部相机的数据话题，获取相机发出的图像数据消息包，注意这个消息包的格式是sensor_msgs::Image，这是ROS的图像数据格式，借助·cv_bridge将其转化为Opencv的数据格式(cv:Mat格式}，然后就可以使用专业的Opencv库函数，然后对这个图像进行处理。</p>
<p>作为第一个试验，使用最简单的cv::imshow()函数来将相机图像显示到窗口里。</p>
<p>首先创建一个新的软件包，用来放置咱们的节点程序，</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>ht@ht-VirtualBox:~/catkin_ws$ cd ~/catkin_ws/src/
ht@ht-VirtualBox:~/catkin_ws/src$ catkin_create_pkg cv_pkg roscpp cv_bridge
Created file cv_pkg/package.xml
Created file cv_pkg/CMakeLists.txt
Created folder cv_pkg/include/cv_pkg
Created folder cv_pkg/src
Successfully created files in /home/ht/catkin_ws/src/cv_pkg. Please adjust the values in package.xml.
ht@ht-VirtualBox:~/catkin_ws/src$ 
</code></pre><p>开始编写节点代码，</p>
<p>首先include ROS的头文件，然后是转换图像格式需要用到的cv_bridge的头文件，图像编码格式image_encodings的头文件，接下来是Opencv的图像处理函数的头文件，以及Opencv的图形化显示函数头文件，下面开始编写正式的程序代码，</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;opencv2/imgproc/imgproc.hpp&gt;
#include &lt;opencv2/highgui/highgui.hpp&gt;

using namespace cv;
</code></pre><p>先是引入cv命名空间，告诉编译器，在这个文件中，所有没有指定命名空间的函数，优先调用cv这个命名空间里的同名函数，cv是Opencv的命名空间，这句代码的作用是简化Opencv函数的书写，就不用再某些函数前面加cv::的前缀了，然后编写主函数，</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730455816472-fb763be0-13af-4086-b922-b6cb5931f02b.png" alt=""></p>
<p>先是初始化节点，然后定义一个NodeHandle对象nh，</p>
<p>用这个nh对象订阅前面所说的 /kinect2/qhd/image_color_rect 话题，</p>
<p>其中kinect2是相机的名称，通常相机会把自己的名称放在话题的最前面，比如realsense等，或者直接叫camera,</p>
<p>qhd是图像分辨率，当一个相机支持多种分辨率时，就会在话题名称中多出这样的分类，所有这个话题名称的意思是，kinect2相机在qhd分辨率下经过畸变校正后的彩色图像，这个话题是相机节点发布的，一旦相机启动后，这个话题里就会源源不断地发出相机图像数据的消息包，咱们只需要订阅这个话题，就能获取这些消息包，接收消息包的缓存长度设置为1，只缓存一帧图像，这样不会累计数据，每次都能读取到最新的图像，实时性会好一些，最后是接收图像消息包的回调函数Cam_RGB_Callback，</p>
<p>接下来创建一个名为RGB的窗口，用来显示接收到的相机图像，最后调用ros::spin()函数，让主函数出于阻塞等待状态，这样节点程序才能保持运行状态，不断获取相机数据，</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>int main(int argc, char **argv)
{
    ros::init(argc,argv,"cv_image_node");

    ros::NodeHandle nh;
    // 接收相机图像消息包，并发送到回调函数进行处理
    ros::Subscriber rgb_sub = nh.subscribe("/kinect2/qhd/image_color_rect", 1, Cam_RGB_Callback);

    namedWindow("RGB");
    ros::spin();

}
</code></pre><p>接下来实现Cam_RGB_Callback回调函数，对接收到的相机图像进行处理，</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>void Cam_RGB_Callback(const sensor_msgs::Image msg)
{
    cv_bridge::CvImagePtr cv_ptr;
    try
    {
        cv_ptr = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::RGB8);
    }
    catch(cv_bridge::Exception&amp; e)
    {
        ROS_ERROR("cv_bridge exception: %s", e.what());
        return;
    }
    Mat imgOriginal = cv_ptr-&gt;image;
    imshow("RGB", imgOriginal);

    waitKey(1);
}
</code></pre><p>这个回调函数在节点接收到一帧新的图像时，就会被调用一次，也就是说，相机1秒钟采集30帧图像的话，这个函数在1秒钟里就会被调用30次，每次它只处理1帧图像，参数msg就是携带了相机图像数据的消息包，在回调函数里，咱们先定义一个Opencv图像类型指针cv_ptr，然后尝试调用cv_bridge的ToCvCopy()函数，将ROS格式的图像数据消息包转换为Opencv格式的图片格式的图片对象，并赋值给cv_ptr指针，ToCvCopy()函数的第二个参数是转换后的图像格式，这里指定的是BGR8，这个格式的结构是，每个像素在图像数组中按照BGR蓝绿红顺序排列，每个颜色占用8位存储空间，也就是BGR每个颜色占用一个字节，算下来每个像素3种颜色，占用了3个字节，这个图像格式转换过程，上下游的数据比较多，会存在转换失败的风险，所以这里使用try... ... catch... ...的组合，在转换失败时提供一个异常处理，避免整个节点程序挂掉，当这个图像格式转换成功后，定义一个Opencv自己的图像对象mgOriginal，从cv_ptr获取转换后的相机图像，然后调用Opencv的imshow{}函数，将相机图像显示到标题为RGB的窗口中去，最后调用waitkey()函数让回调函数暂停一会，留出一些时间给imshow()函数完成图像显示工作，这里的参数1表示暂停1毫秒。</p>
<pre data-role="codeBlock" data-info="cpp" class="language-cpp cpp"><code><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;ros/ros.h&gt;</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;cv_bridge/cv_bridge.h&gt;</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;sensor_msgs/image_encodings.h&gt;</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;opencv2/imgproc/imgproc.hpp&gt;</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;opencv2/highgui/highgui.hpp&gt;</span></span>

<span class="token keyword keyword-using">using</span> <span class="token keyword keyword-namespace">namespace</span> cv<span class="token punctuation">;</span>

<span class="token keyword keyword-void">void</span> <span class="token function">Cam_RGB_Callback</span><span class="token punctuation">(</span><span class="token keyword keyword-const">const</span> sensor_msgs<span class="token double-colon punctuation">::</span><span class="token type-opencl-host-cpp keyword">Image</span> msg<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
    cv_bridge<span class="token double-colon punctuation">::</span>CvImagePtr cv_ptr<span class="token punctuation">;</span>
    <span class="token keyword keyword-try">try</span>
        <span class="token punctuation">{</span>
            cv_ptr <span class="token operator">=</span> cv_bridge<span class="token double-colon punctuation">::</span><span class="token function">toCvCopy</span><span class="token punctuation">(</span>msg<span class="token punctuation">,</span> sensor_msgs<span class="token double-colon punctuation">::</span>image_encodings<span class="token double-colon punctuation">::</span>RGB8<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token keyword keyword-catch">catch</span><span class="token punctuation">(</span>cv_bridge<span class="token double-colon punctuation">::</span>Exception<span class="token operator">&amp;</span> e<span class="token punctuation">)</span>
        <span class="token punctuation">{</span>
            <span class="token function">ROS_ERROR</span><span class="token punctuation">(</span><span class="token string">"cv_bridge exception: %s"</span><span class="token punctuation">,</span> e<span class="token punctuation">.</span><span class="token function">what</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
            <span class="token keyword keyword-return">return</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    Mat imgOriginal <span class="token operator">=</span> cv_ptr<span class="token operator">-&gt;</span>image<span class="token punctuation">;</span>
    <span class="token function">imshow</span><span class="token punctuation">(</span><span class="token string">"RGB"</span><span class="token punctuation">,</span> imgOriginal<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token function">waitKey</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token keyword keyword-int">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword keyword-int">int</span> argc<span class="token punctuation">,</span> <span class="token keyword keyword-char">char</span> <span class="token operator">*</span><span class="token operator">*</span>argv<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
    ros<span class="token double-colon punctuation">::</span><span class="token function">init</span><span class="token punctuation">(</span>argc<span class="token punctuation">,</span>argv<span class="token punctuation">,</span><span class="token string">"cv_image_node"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    ros<span class="token double-colon punctuation">::</span>NodeHandle nh<span class="token punctuation">;</span>
    <span class="token comment">// 接收相机图像消息包，并发送到回调函数进行处理</span>
    ros<span class="token double-colon punctuation">::</span>Subscriber rgb_sub <span class="token operator">=</span> nh<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span><span class="token string">"/kinect2/qhd/image_color_rect"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Cam_RGB_Callback<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token function">namedWindow</span><span class="token punctuation">(</span><span class="token string">"RGB"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    ros<span class="token double-colon punctuation">::</span><span class="token function">spin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token punctuation">}</span>
</code></pre><p>添加编译规则  打开CMakeLists.txt文件</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code># find_package(Boost REQUIRED COMPONENTS system)
find_package(OpenCV REQUIRED)
</code></pre><p>引入Opencv的环境配置参数，其中REQUIRED的意思是，这个Opencv的环境参数是必须的，如果系统重找不到Opencv，那么编译过程就会终止，因为没有Opencv的话，后面的节点编译也会失败，索性在这里就结束得了，</p>
<p>然后在下面找到include_directories，在里面添加Opencv的头文件路径，<img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730469027797-6e573287-6463-4596-978c-6c5e88eb2cb9.png" alt="">，</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>## Your package locations should be listed before other locations
include_directories(
# include
  ${catkin_INCLUDE_DIRS}
  ${OpenCV_INCLUDE_DIRS}
)
</code></pre><p>如果不添加这个，后面编译节点的时候会提示找不到OpenCV的头文件，</p>
<p>最后添加节点编译规则，</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730469342211-6d80bee5-34b7-44b7-832a-fec65b994c3e.png" alt=""></p>
<p>这里与之前有点不一样，就是在链接库的规则里新增了一个OPenCV的库文件列表，如果没有会报错，提示找不到OpenCV函数对应的库文件，</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>add_executable(cv_image_node src/cv_image_node.cpp)
add_dependencies(cv_image_node  ${${PROJECT_NAME}_EXPORTED_TARGETS} ${catkin_EXPORTED_TARGETS})
target_link_libraries(cv_image_node 
  ${catkin_LIBRARIES}${OpenCV_LIBS}
)
</code></pre><p><em><u>从上述过程可以看到，在CMake软件包中导入一个第三方函数库，基本操作就是。先find_package，然后添加include头文件路径，最后在为节点程序添加编译规则时多加一条库文件列表。</u></em></p>
<p>编译并运行</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>catkin_make 或者ctrl+shift+B

1.启动仿真环境
roslaunch wpr_simulation wpb_balls.launch
2.运行cv_image_node节点文件
rosrun cv_pkg cv_image_node
3.移动相机视野下小球
rosrun wpr_simulation ball_random_move
</code></pre><p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730470692188-44ee383e-8561-45cf-a2cc-4c9c1535d8f3.png" alt=""></p>
<p>注意：可能缺失一些依赖报错</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>Scanning dependencies of target cv_image_node
[ 12%] Building CXX object cv_pkg/CMakeFiles/cv_image_node.dir/src/cv_image_node.cpp.o
make[2]: *** 没有规则可制作目标“/usr/lib/x86_64-linux-gnu/libconsole_bridge.so.0.4opencv_calib3d”，由“/home/ht/catkin_ws/devel/lib/cv_pkg/cv_image_node” 需求。 停止。
make[1]: *** [CMakeFiles/Makefile2:3382：cv_pkg/CMakeFiles/cv_image_node.dir/all] 错误 2
make: *** [Makefile:141：all] 错误 2
Invoking "make -j1 -l1" failed

 *  终端进程“/usr/bin/bash '-c', 'catkin_make --directory /home/ht/catkin_ws -DCMAKE_BUILD_TYPE=RelWithDebInfo'”已终止，退出代码: 1。 
 *  终端将被任务重用，按任意键关闭。
</code></pre><p>错误信息显示在编译 <code>cv_image_node</code> 时出现了问题，提示缺少库文件 <code>libconsole_bridge.so.0.4</code>。</p>
<ul>
<li><code>libconsole_bridge</code> 是 ROS 常用的依赖项之一。可以尝试重新安装相关库来解决这个问题：</li>
</ul>
<pre data-role="codeBlock" data-info="bash" class="language-bash bash"><code><span class="token function">sudo</span> <span class="token function">apt-get</span> update
<span class="token function">sudo</span> <span class="token function">apt-get</span> <span class="token function">install</span> libconsole-bridge-dev
</code></pre><pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>ht@ht-VirtualBox:~/catkin_ws/src$ sudo apt-get install libconsole-bridge-dev
正在读取软件包列表... 完成
正在分析软件包的依赖关系树       
正在读取状态信息... 完成       
libconsole-bridge-dev 已经是最新版 (0.4.4+dfsg-1build1)。
libconsole-bridge-dev 已设置为手动安装。
升级了 0 个软件包，新安装了 0 个软件包，要卸载 0 个软件包，有 416 个软件包未被升级。
</code></pre><pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>ht@ht-VirtualBox:~/catkin_ws/src$ ls /usr/lib/x86_64-linux-gnu/libconsole_bridge*
/usr/lib/x86_64-linux-gnu/libconsole_bridge.so
/usr/lib/x86_64-linux-gnu/libconsole_bridge.so.0.4
ht@ht-VirtualBox:~/catkin_ws/src$ 
</code></pre><p>从输出可以看到，<code>libconsole_bridge.so</code> 和 <code>libconsole_bridge.so.0.4</code> 文件都存在。</p>
<p>错误信息显示目标库文件路径 <code>libconsole_bridge.so.0.4opencv_calib3d</code> 不正确，它将 <code>libconsole_bridge.so.0.4</code> 和 <code>opencv_calib3d</code> 错误地连接在一起了。此问题可能是由于 <code>CMakeLists.txt</code> 中配置错误或路径引用问题导致的。可以尝试以下解决方案：</p>
<ol>
<li><strong>检查 CMakeLists.txt 中的库路径</strong>：
<ul>
<li>在 <code>cv_pkg</code> 的 <code>CMakeLists.txt</code> 中，查看是否有拼接错误的路径。例如，确保 OpenCV 和 <code>console_bridge</code> 的路径和依赖库是分别正确添加的。</li>
<li>确保以下部分配置正确：</li>
</ul>
</li>
</ol>
<pre data-role="codeBlock" data-info="cmake" class="language-cmake cmake"><code><span class="token keyword keyword-find_package">find_package</span><span class="token punctuation">(</span>OpenCV REQUIRED<span class="token punctuation">)</span>
<span class="token keyword keyword-find_package">find_package</span><span class="token punctuation">(</span>console_bridge REQUIRED<span class="token punctuation">)</span>
<span class="token keyword keyword-include_directories">include_directories</span><span class="token punctuation">(</span><span class="token punctuation">${</span>OpenCV_INCLUDE_DIRS<span class="token punctuation">}</span> <span class="token punctuation">${</span>console_bridge_INCLUDE_DIRS<span class="token punctuation">}</span><span class="token punctuation">)</span>
<span class="token keyword keyword-target_link_libraries">target_link_libraries</span><span class="token punctuation">(</span>cv_image_node <span class="token punctuation">${</span>OpenCV_LIBS<span class="token punctuation">}</span> <span class="token punctuation">${</span>console_bridge_LIBRARIES<span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre><ol start="2">
<li><strong>清理并重新编译</strong>：<br>
重新清理工作区，确保没有残留的缓存导致路径问题：</li>
</ol>
<pre data-role="codeBlock" data-info="bash" class="language-bash bash"><code><span class="token builtin class-name">cd</span> ~/catkin_ws
<span class="token function">rm</span> <span class="token parameter variable">-rf</span> build devel
catkin_make
</code></pre><ol start="3">
<li><strong>检查 OpenCV 配置</strong>：<br>
确保 OpenCV 正确安装，并且在 CMakeLists.txt 中的引用是 <code>opencv_calib3d</code> 而不是拼接在一起的 <code>libconsole_bridge.so.0.4opencv_calib3d</code>。</li>
</ol>
<p>尝试以上步骤后重新编译，查看问题是否解决。</p>
<p><strong><font style="color:#DF2A3F;">修正有效</font></strong></p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730472539456-28f93bc2-a8ee-4bcf-a5fa-0856496663bd.png" alt=""></p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730472568062-4f49aaee-466f-43a4-8307-f2f217139619.png" alt=""></p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730472586953-9e0bcb61-1738-4d91-9390-e7a3571348ee.png" alt=""></p>
<h2 id="ros-颜色目标识别与定位的-c-实现">ROS 颜色目标识别与定位的 C++ 实现 </h2>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730551008088-dd1b12e6-ff4e-43bb-88b8-26cc833972aa.png" alt=""></p>
<p>学习如何使用OpenCV对相机图像数据进行处理，主要是对几个颜色的球进行颜色特征提取以及空间定位，在进行具体操作前，咱们先进行任务的分解，</p>
<p>第一步，对机器人视觉图像进行颜色空间转换，从RGB空间转换到HSV空间，</p>
<p>第二步·，对转换后的图像进行二值化处理，将目标物体分割提取出来，</p>
<p>第三步，对提取到的目标像素进行计算统计，得出目标物的质心坐标。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730551251377-fd2d88c3-9ace-45fd-b9a8-61237692b423.png" alt=""></p>
<p>通常咱们对颜色的描述，使用的是RGB红绿蓝三原色描述法，也就是所有的颜色都可以使用不同数值的三原色进行描述，于是这就构成了RGB颜色空间，</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730552054386-f5c262e8-f778-4874-8d42-90ca10f160e7.png" alt=""></p>
<p><em><strong>所有的颜色都可以用这个正方体空间中的一个点来表示</strong></em>，仔细观察可以发现，不同的颜色区域在空间中的分布并不规则，有的颜色集中在顶角上，有的颜色在立方体的中段，很难用一种统一的几何方法将不同颜色分割出来，最麻烦的是颜色的饱和度和亮度也混杂在这三个数值维度中，难以单独进行分割。在实际的应用中也会发现，直接对RGB进行数值分割会受到光照条件的影响，不同光照条件下，颜色的饱和度和亮度会有所不同，导致RGB数值产生较大变化，直接对RGB进行数值分割的方法，就会失效，所以_<strong>一般的做法是将颜色的描述从RGB空间转换到HSV空间去进行数值分割</strong>_。</p>
<p>HSV是Hue（色调） Saturation（饱和度） Value（亮度）三个单词的首字母缩写，<em><strong>HSV的空间模型是一个倒立的圆锥形，其中色调H表示为颜色点围绕圆锥中心轴旋转的角度，饱和度S表示为颜色点与圆锥中心轴的距离，亮度V表示为颜色点与圆锥顶点的距离</strong></em>，为了便于进行几何分割，一般会把圆锥底面圆单独拿出来，</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730552520449-3e60801b-2b0b-4d19-b0da-20cf16210f49.png" alt=""><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730552595054-13bf9e9b-f6c2-4370-b104-fee26e1a1bb8.png" alt=""></p>
<p>可以看到这相当于一个颜色的极坐标系，咱们从红色这条半径给它切开，将它的极点也就是圆的中心点拉长成一条边，就变成咱们熟悉的直角坐标系，色调H变成直角坐标系的一个轴，这就很能明显的看出，不同的颜色在H轴上是逐渐过渡的，咱们只需要在H轴上设定一组最大值和最小值，就能将某种特定颜色分割出来，这里的纵轴是颜色饱和度S，可以看到越往上值越大颜色越鲜艳，越往下值越小颜色越暗淡，所有通常也会给它设定一组最大值和最小值来限定颜色的鲜艳程度，最后还有一个V会单独作为一个维度，这就把光照条件对颜色的影响给剥离出来了，给它也设定一组最大值和最小值，</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730553156061-27937fc7-8ef0-4b2a-b7dc-8bfb0f355c7e.png" alt=""><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730553373906-1af5b1c6-5576-4a82-8445-9196b277caa6.png" alt=""></p>
<p><em><strong>通过这三组数值，一共6个阈值，就能够将某种纯度的颜色从颜色空间里分割出来</strong></em>。</p>
<p>颜色空间转换在OpenCV里有现成的函数，不需要咱们来进行计算转换，咱们就只要设置好这6个分割阈值就行了。通过转换颜色空间，设置分割阈值，就能把具有某种颜色特征的像素从相机图像中提取出来，</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730553717850-bee8939f-7334-40a6-9af9-23f2df67add9.png" alt="">、</p>
<p>得到这样一个黑白图片，其中白色区域，为符合阈值特征的像素点集合，黑色区域为其他像素，这就是图像特征的二值化。假如把这些符合阈值条件的像素点集合，认定为就是某个物体的形状，那么通过对这些像素点进行坐标值的均值计算，就能得到这个物体的质心，对于圆形物体来说，质心就是它的中心，<em><strong>这样就实现了对图像中具备某种颜色特征的物体进行空间定位的效果</strong></em>。</p>
<p>接下来进行代码实现，</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;opencv2/imgproc/imgproc.hpp&gt;
#include &lt;opencv2/highgui/highgui.hpp&gt;

using namespace cv;   // 方便使用OpenCV函数
using namespace std;  // 方便使用Vector容器
</code></pre><p>定义6个变量用于存储颜色特征阈值，</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>static int iLowH = 10;
static int iHighH = 40;

static int iLowS = 90;
static int iHighS = 255;

static int iLowV = 1;
static int iHighV = 255;
</code></pre><p>下面开始编写main主函数，</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>int main(int argc, char **argv)
{
    ros::init(argc, argv, "cv_hsv_node");

    ros::NodeHandle nh;
    ros::Subscriber rgb_sub = nh.subscribe("/kinect2/qhd/image_color_rect", 1, Cam_RGB_Callback);

    // 生成图像显示和参数调节的窗口
    namedWindow("Threshold", WINDOW_AUTOSIZE);
    // 调用createTrackbar()创建滑杆控件,动态调节参数 （滑杆名称，滑杆隶属窗口标题，阈值变量，
    createTrackbar("LowH", "Threshold", &amp;iLowH, 179);  //Hue (0 - 179)  （0-360）缩小一半--》（0，179）
    createTrackbar("HighH", "Threshold", &amp;iHighH, 179);

    createTrackbar("LowS", "Threshold", &amp;iLowS, 255);  //Saturation (0 - 255)
    createTrackbar("HighS", "Threshold", &amp;iHighS, 255);

    createTrackbar("LowV", "Threshold", &amp;iLowV, 255);  //Value (0 - 255)
    createTrackbar("HighV", "Threshold", &amp;iHighV, 255);

    namedWindow("RGB");
    namedWindow("HSV");
    namedWindow("Result");

    ros::spin();
}
</code></pre><p>最后是编写回调函数，</p>
<p>和前面获取相机图像一样，先将接收到的消息包里的图像数据格式从ROS的Image格式转换为OpenCV的Mat格式，暂存在imgOriginal对象里，然后定义一个Mat对象imgHSV，调用cvtColor()函数将imgOriginal的RGB格式转化为HSV格式，然后存储到imgHSV对象中去，再对HSV中的V值也就是亮度值进行均衡化，因为在大多数图像中，大多数像素的亮度值容易拥挤在一个很小的区间里，造成的结果是亮度阈值的可调节范围太小了，区分度不高，所有这里做一下均衡化，让亮度值的分布范围变大，方便进行阈值分割。</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>void Cam_RGB_Callback(const sensor_msgs::Image msg)
{
    cv_bridge::CvImagePtr cv_ptr;
    try
    {
        cv_ptr = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::RGB8);
    }
    catch(cv_bridge::Exception&amp; e)
    {
        ROS_ERROR("cv_bridge exception: %s", e.what());
        return;
    }
    Mat imgOriginal = cv_ptr-&gt;image;

    //将RGB图片转换成HSV
    Mat imgHSV;
    cvtColor(imgOriginal, imgHSV, COLOR_BGR2HSV);
    //在HSV空间做直方图均衡化
    vector&lt;Mat&gt; hsvSplit;
    split(imgHSV, hsvSplit);
    equalizeHist(hsvSplit[2], hsvSplit[2]);
    merge(hsvSplit, imgHSV);

}
</code></pre><p>将HSV的数值处理好后，就可以使用事先定义好的三组颜色阈值对HSV图像进行颜色分割了，这个分割操作是对图像中所有像素进行遍历，将符合阈值条件的像素标记为白色，不符合阈值条件的标记为黑色，所有像素的分割结果保存在imgThresholded对象里，最后显示出来是黑白图像。</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>    //使用上面的Hue, Saturation和Value的阈值范围对图像进行二值化
    Mat imgThresholded;
    inRange(imgHSV, Scalar(iLowH, iLowS, iLowV), Scalar(iHigehH, iHighS, iHighV), imgThresholded);

    //开操作(去除一些噪点)
    Mat element = getStructuringElement(MORPH_RECT, Size(5,5));
    morphologyEx(imgThresholded, imgThresholded, MORPH_OPEN， element);

    //闭操作
    morphologyEx(imgThresholded, imgThresholded, MORPH_CLOSE， element);
</code></pre><p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730557944853-a9ab773c-ca62-4199-a340-01f6fdd0dace.png" alt=""><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730558043048-10427e09-f7d0-401c-ae49-3d5ccdd0be29.png" alt=""></p>
<p>接下来对这个分割结果进行一个开操作，也就是腐蚀，去除一些游离的像素噪点，再进行一个闭操作，也就是膨胀，让没被腐蚀掉的主体区域又恢复到原来的大小，得到目标结果图像。其中白色区域就是目标物体所占据的像素区域，这个图像里的每一个像素为一个字节，白色区域里的每个像素数值为oxFF，也就是255，单个字节的最大值，黑色区域的像素数值为0，单个字节的最小值。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730558601652-3023a95e-2776-4e72-ad01-76f0c6a93435.png" alt=""></p>
<p>接下来就要把白色区域的中心坐标计算出来，就可以认为是目标物体在图像里的空间位置，</p>
<p>首先咱们定义两个target变量，用来存储计算后的目标物的横坐标和纵坐标，定义一个nPixCount变量，用来记录目标物所占据的像素点数量，再定义三个变量，分别读取目标结果图像分辨率的横向数值和纵向数值，以及目标结果图像的通道数，这个通道是指的每个像素占用了几个字节，有了这些数据，咱们就可以进行目标中心坐标的计算了。在计算之前，得了解一下，这个imgThresholded对象里，图像数据的结构，这个目标结果图像里的数据结构和之前学过的栅格地图非常像，也是将一个二维阵列里的像素一行一行拼接起来，变成一个一维数组，</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730559727910-6fd02f19-8802-478c-a838-2441cb09509b.png" alt=""><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730559774942-ca9444dd-0d75-449f-ab40-5bd65cf21351.png" alt=""></p>
<p>在目标结果图像imgThresholded对象中，这个数组名字叫做data，可以构建一个双重嵌套的for循环，外层的for循环是对行数进行遍历，内层的for循环是对每一行的横向排列的像素进行遍历，从中寻找像素值为255，也就是白色区域的像素，将他的横坐标和纵坐标的数值累加到target变量中去，同时记录白色像素的点数，当对目标结果图像的所有像素都遍历完成之后，看看是否找到白色像素点，如果白色像素点数量大于0，说明图像中存在目标物，那么把累加后的坐标值除以目标像素的点数，这样就得到了白色像素区域的质心坐标，即目标球的中心坐标，</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>    //遍历二值化后的图像数据
    int nTargetX = 0;
    int nTargetY = 0;
    int nPixCount = 0;
    int nImgWidth = imgThresholded.cols;
    int nImgHeight = imgThresholded.rows;
    int nImgChannels = imgThresholded.channels();
    for (int y = 0; y &lt; nImgHeight; y++)
    {
        for(int x = 0; x &lt; nImgWidth; x++)
        {
            if(imgThresholded.data[y*nImgWidth + x] == 255)
            {
                nTargetX += x;
                nTargetY += y;
                nPixCount ++;
            }
        }
    }

    if(nPixCount &gt; 0)
    {
        nTargetX /= nPixCount;
        nTargetY /= nPixCount;
        printf("颜色质心坐标(%d, %d) 点数 = %d\n",nTargetX, nTargetY, nPixCount);
        //画坐标
        Point line_begin = Point(nTargetX-10, nTargetY);
        Point line_end = Point(nTargetX+10, nTargetY);
        line(imgOriginal,line_begin,line_end,Scalar(255,0,0));

        line_begin.x = nTargetX; line_begin.y = nTargetY-10;
        line_end.x = nTargetX; line_end.y = nTargetY+10;
        line(imgOriginal,line_begin,line_end,Scalar(255,0,0));
    }
    else{
        printf("目标颜色消失...\n");
    }

    // 显示处理结果
    imshow("RGB", imgOriginal);
    imshow("HSV", imgHSV);
    imshow("Result", imgThresholded);
    waitKey(5);
</code></pre><p>然后使用OpenCV函数的line函数在相机图像中目标球中心点的位置画两条线段，第一条线段是从目标点左侧10个像素的位置画到目标点右侧10个像素位置，颜色为蓝色，第二条线段是从目标点上方10个像素位置画到目标点下发10个像素位置，颜色也为蓝色，方便在图像中观察目标结果，如果图像中没有找到目标颜色的像素，说明目标球已经移动到视野之外了，提示目标已消失，最后调用imshow()函数显示图像结果，waitkey停顿5毫秒让图像显示执行完毕。回调函数到此结束。</p>
<p>完整代码：</p>
<pre data-role="codeBlock" data-info="cpp" class="language-cpp cpp"><code><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;ros/ros.h&gt;</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;cv_bridge/cv_bridge.h&gt;</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;sensor_msgs/image_encodings.h&gt;</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;opencv2/imgproc/imgproc.hpp&gt;</span></span>
<span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;opencv2/highgui/highgui.hpp&gt;</span></span>

<span class="token keyword keyword-using">using</span> <span class="token keyword keyword-namespace">namespace</span> cv<span class="token punctuation">;</span>
<span class="token keyword keyword-using">using</span> <span class="token keyword keyword-namespace">namespace</span> std<span class="token punctuation">;</span>

<span class="token keyword keyword-static">static</span> <span class="token keyword keyword-int">int</span> iLowH <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span>
<span class="token keyword keyword-static">static</span> <span class="token keyword keyword-int">int</span> iHighH <span class="token operator">=</span> <span class="token number">40</span><span class="token punctuation">;</span>

<span class="token keyword keyword-static">static</span> <span class="token keyword keyword-int">int</span> iLowS <span class="token operator">=</span> <span class="token number">90</span><span class="token punctuation">;</span>
<span class="token keyword keyword-static">static</span> <span class="token keyword keyword-int">int</span> iHighS <span class="token operator">=</span> <span class="token number">255</span><span class="token punctuation">;</span>

<span class="token keyword keyword-static">static</span> <span class="token keyword keyword-int">int</span> iLowV <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>
<span class="token keyword keyword-static">static</span> <span class="token keyword keyword-int">int</span> iHighV <span class="token operator">=</span> <span class="token number">255</span><span class="token punctuation">;</span>

<span class="token keyword keyword-void">void</span> <span class="token function">Cam_RGB_Callback</span><span class="token punctuation">(</span><span class="token keyword keyword-const">const</span> sensor_msgs<span class="token double-colon punctuation">::</span><span class="token type-opencl-host-cpp keyword">Image</span> msg<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
    cv_bridge<span class="token double-colon punctuation">::</span>CvImagePtr cv_ptr<span class="token punctuation">;</span>
    <span class="token keyword keyword-try">try</span>
    <span class="token punctuation">{</span>
        cv_ptr <span class="token operator">=</span> cv_bridge<span class="token double-colon punctuation">::</span><span class="token function">toCvCopy</span><span class="token punctuation">(</span>msg<span class="token punctuation">,</span> sensor_msgs<span class="token double-colon punctuation">::</span>image_encodings<span class="token double-colon punctuation">::</span>RGB8<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    <span class="token keyword keyword-catch">catch</span><span class="token punctuation">(</span>cv_bridge<span class="token double-colon punctuation">::</span>Exception<span class="token operator">&amp;</span> e<span class="token punctuation">)</span>
    <span class="token punctuation">{</span>
        <span class="token function">ROS_ERROR</span><span class="token punctuation">(</span><span class="token string">"cv_bridge exception: %s"</span><span class="token punctuation">,</span> e<span class="token punctuation">.</span><span class="token function">what</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token keyword keyword-return">return</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    Mat imgOriginal <span class="token operator">=</span> cv_ptr<span class="token operator">-&gt;</span>image<span class="token punctuation">;</span>

    <span class="token comment">//将RGB图片转换成HSV</span>
    Mat imgHSV<span class="token punctuation">;</span>
    <span class="token function">cvtColor</span><span class="token punctuation">(</span>imgOriginal<span class="token punctuation">,</span> imgHSV<span class="token punctuation">,</span> COLOR_BGR2HSV<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">//在HSV空间做直方图均衡化</span>
    vector<span class="token operator">&lt;</span>Mat<span class="token operator">&gt;</span> hsvSplit<span class="token punctuation">;</span>
    <span class="token function">split</span><span class="token punctuation">(</span>imgHSV<span class="token punctuation">,</span> hsvSplit<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">equalizeHist</span><span class="token punctuation">(</span>hsvSplit<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> hsvSplit<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">merge</span><span class="token punctuation">(</span>hsvSplit<span class="token punctuation">,</span> imgHSV<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">//使用上面的Hue, Saturation和Value的阈值范围对图像进行二值化</span>
    Mat imgThresholded<span class="token punctuation">;</span>
    <span class="token function">inRange</span><span class="token punctuation">(</span>imgHSV<span class="token punctuation">,</span> <span class="token function">Scalar</span><span class="token punctuation">(</span>iLowH<span class="token punctuation">,</span> iLowS<span class="token punctuation">,</span> iLowV<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token function">Scalar</span><span class="token punctuation">(</span>iHighH<span class="token punctuation">,</span> iHighS<span class="token punctuation">,</span> iHighV<span class="token punctuation">)</span><span class="token punctuation">,</span> imgThresholded<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">//开操作(去除一些噪点)</span>
    Mat element <span class="token operator">=</span> <span class="token function">getStructuringElement</span><span class="token punctuation">(</span>MORPH_RECT<span class="token punctuation">,</span> <span class="token function">Size</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">morphologyEx</span><span class="token punctuation">(</span>imgThresholded<span class="token punctuation">,</span> imgThresholded<span class="token punctuation">,</span> MORPH_OPEN<span class="token punctuation">,</span> element<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">//闭操作（连接一些连通域）</span>
    <span class="token function">morphologyEx</span><span class="token punctuation">(</span>imgThresholded<span class="token punctuation">,</span> imgThresholded<span class="token punctuation">,</span> MORPH_CLOSE<span class="token punctuation">,</span> element<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">//遍历二值化后的图像数据</span>
    <span class="token keyword keyword-int">int</span> nTargetX <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
    <span class="token keyword keyword-int">int</span> nTargetY <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
    <span class="token keyword keyword-int">int</span> nPixCount <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
    <span class="token keyword keyword-int">int</span> nImgWidth <span class="token operator">=</span> imgThresholded<span class="token punctuation">.</span>cols<span class="token punctuation">;</span>
    <span class="token keyword keyword-int">int</span> nImgHeight <span class="token operator">=</span> imgThresholded<span class="token punctuation">.</span>rows<span class="token punctuation">;</span>
    <span class="token keyword keyword-int">int</span> nImgChannels <span class="token operator">=</span> imgThresholded<span class="token punctuation">.</span><span class="token function">channels</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword keyword-for">for</span> <span class="token punctuation">(</span><span class="token keyword keyword-int">int</span> y <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> y <span class="token operator">&lt;</span> nImgHeight<span class="token punctuation">;</span> y<span class="token operator">++</span><span class="token punctuation">)</span>
    <span class="token punctuation">{</span>
        <span class="token keyword keyword-for">for</span><span class="token punctuation">(</span><span class="token keyword keyword-int">int</span> x <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> x <span class="token operator">&lt;</span> nImgWidth<span class="token punctuation">;</span> x<span class="token operator">++</span><span class="token punctuation">)</span>
        <span class="token punctuation">{</span>
            <span class="token keyword keyword-if">if</span><span class="token punctuation">(</span>imgThresholded<span class="token punctuation">.</span>data<span class="token punctuation">[</span>y<span class="token operator">*</span>nImgWidth <span class="token operator">+</span> x<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">255</span><span class="token punctuation">)</span>
            <span class="token punctuation">{</span>
                nTargetX <span class="token operator">+=</span> x<span class="token punctuation">;</span>
                nTargetY <span class="token operator">+=</span> y<span class="token punctuation">;</span>
                nPixCount <span class="token operator">++</span><span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>

    <span class="token keyword keyword-if">if</span><span class="token punctuation">(</span>nPixCount <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token punctuation">{</span>
        nTargetX <span class="token operator">/=</span> nPixCount<span class="token punctuation">;</span>
        nTargetY <span class="token operator">/=</span> nPixCount<span class="token punctuation">;</span>
        <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"颜色质心坐标(%d, %d) 点数 = %d\n"</span><span class="token punctuation">,</span>nTargetX<span class="token punctuation">,</span> nTargetY<span class="token punctuation">,</span> nPixCount<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">//画坐标</span>
        Point line_begin <span class="token operator">=</span> <span class="token function">Point</span><span class="token punctuation">(</span>nTargetX<span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span> nTargetY<span class="token punctuation">)</span><span class="token punctuation">;</span>
        Point line_end <span class="token operator">=</span> <span class="token function">Point</span><span class="token punctuation">(</span>nTargetX<span class="token operator">+</span><span class="token number">10</span><span class="token punctuation">,</span> nTargetY<span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token function">line</span><span class="token punctuation">(</span>imgOriginal<span class="token punctuation">,</span>line_begin<span class="token punctuation">,</span>line_end<span class="token punctuation">,</span><span class="token function">Scalar</span><span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

        line_begin<span class="token punctuation">.</span>x <span class="token operator">=</span> nTargetX<span class="token punctuation">;</span> line_begin<span class="token punctuation">.</span>y <span class="token operator">=</span> nTargetY<span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">;</span>
        line_end<span class="token punctuation">.</span>x <span class="token operator">=</span> nTargetX<span class="token punctuation">;</span> line_end<span class="token punctuation">.</span>y <span class="token operator">=</span> nTargetY<span class="token operator">+</span><span class="token number">10</span><span class="token punctuation">;</span>
        <span class="token function">line</span><span class="token punctuation">(</span>imgOriginal<span class="token punctuation">,</span>line_begin<span class="token punctuation">,</span>line_end<span class="token punctuation">,</span><span class="token function">Scalar</span><span class="token punctuation">(</span><span class="token number">255</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    <span class="token keyword keyword-else">else</span><span class="token punctuation">{</span>
        <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"目标颜色消失...\n"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token comment">// 显示处理结果</span>
    <span class="token function">imshow</span><span class="token punctuation">(</span><span class="token string">"RGB"</span><span class="token punctuation">,</span> imgOriginal<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">imshow</span><span class="token punctuation">(</span><span class="token string">"HSV"</span><span class="token punctuation">,</span> imgHSV<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">imshow</span><span class="token punctuation">(</span><span class="token string">"Result"</span><span class="token punctuation">,</span> imgThresholded<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">waitKey</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token keyword keyword-int">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword keyword-int">int</span> argc<span class="token punctuation">,</span> <span class="token keyword keyword-char">char</span> <span class="token operator">*</span><span class="token operator">*</span>argv<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
    ros<span class="token double-colon punctuation">::</span><span class="token function">init</span><span class="token punctuation">(</span>argc<span class="token punctuation">,</span> argv<span class="token punctuation">,</span> <span class="token string">"cv_hsv_node"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    ros<span class="token double-colon punctuation">::</span>NodeHandle nh<span class="token punctuation">;</span>
    ros<span class="token double-colon punctuation">::</span>Subscriber rgb_sub <span class="token operator">=</span> nh<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span><span class="token string">"/kinect2/qhd/image_color_rect"</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> Cam_RGB_Callback<span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token comment">// 生成图像显示和参数调节的窗口</span>
    <span class="token function">namedWindow</span><span class="token punctuation">(</span><span class="token string">"Threshold"</span><span class="token punctuation">,</span> WINDOW_AUTOSIZE<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// 调用createTrackbar()创建滑杆控件,动态调节参数 （滑杆名称，滑杆隶属窗口标题，阈值变量，</span>
    <span class="token function">createTrackbar</span><span class="token punctuation">(</span><span class="token string">"LowH"</span><span class="token punctuation">,</span> <span class="token string">"Threshold"</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>iLowH<span class="token punctuation">,</span> <span class="token number">179</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//Hue (0 - 179)  （0-360）缩小一半--》（0，179）</span>
    <span class="token function">createTrackbar</span><span class="token punctuation">(</span><span class="token string">"HighH"</span><span class="token punctuation">,</span> <span class="token string">"Threshold"</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>iHighH<span class="token punctuation">,</span> <span class="token number">179</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token function">createTrackbar</span><span class="token punctuation">(</span><span class="token string">"LowS"</span><span class="token punctuation">,</span> <span class="token string">"Threshold"</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>iLowS<span class="token punctuation">,</span> <span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//Saturation (0 - 255)</span>
    <span class="token function">createTrackbar</span><span class="token punctuation">(</span><span class="token string">"HighS"</span><span class="token punctuation">,</span> <span class="token string">"Threshold"</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>iHighS<span class="token punctuation">,</span> <span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token function">createTrackbar</span><span class="token punctuation">(</span><span class="token string">"LowV"</span><span class="token punctuation">,</span> <span class="token string">"Threshold"</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>iLowV<span class="token punctuation">,</span> <span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">;</span>  <span class="token comment">//Value (0 - 255)</span>
    <span class="token function">createTrackbar</span><span class="token punctuation">(</span><span class="token string">"HighV"</span><span class="token punctuation">,</span> <span class="token string">"Threshold"</span><span class="token punctuation">,</span> <span class="token operator">&amp;</span>iHighV<span class="token punctuation">,</span> <span class="token number">255</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    <span class="token function">namedWindow</span><span class="token punctuation">(</span><span class="token string">"RGB"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">namedWindow</span><span class="token punctuation">(</span><span class="token string">"HSV"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">namedWindow</span><span class="token punctuation">(</span><span class="token string">"Result"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

    ros<span class="token double-colon punctuation">::</span><span class="token function">spin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
</code></pre><p>添加节点文件编译规则</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>add_executable(cv_hsv_node src/cv_hsv_node.cpp)
add_dependencies(cv_hsv_node  ${${PROJECT_NAME}_EXPORTED_TARGETS} ${catkin_EXPORTED_TARGETS})
target_link_libraries(cv_hsv_node 
  ${catkin_LIBRARIES} ${OpenCV_LIBS} ${console_bridge_LIBRARIES}
)
</code></pre><p>catkin_make编译一下，</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>启动仿真环境 roslaunch wpr_simulation wpb_balls.launch
运行节点代码 rosrun cv_pkg cv_hsv_node 
移动小球 rosrun wpr_simulation ball_random_move
</code></pre><p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730613581246-5d66f14d-566d-463d-af1f-22f58d8bb117.png" alt=""><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730613740725-fd2db546-57f9-47e6-be25-a1daac0cea30.png" alt=""><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730613602822-3582d58f-3ef5-4af2-8e97-d4f78edf7009.png" alt=""><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730613624789-3841c6e0-3596-4a9c-8f19-b8af73f7bb0f.png" alt=""><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730613651823-f19263c9-a6e7-432b-8530-c557b1c9cfb9.png" alt=""></p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730613855514-847015a1-6c96-4d09-b3c4-c4fc57145494.png" alt="">移动小球 蓝色标记也会紧紧跟随。</p>
<p><em>不知道为啥，原本橙色的球在虚拟机变成浅蓝色</em>？下图为up主效果。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730614056719-f5fef8c5-a68d-4d7b-88ce-811191d1f57e.png" alt=""></p>
<h2 id="ros-颜色目标跟随的-c-实现">ROS 颜色目标跟随的 C++ 实现 </h2>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730614176776-7a467e04-d89a-41f9-8fb1-917662c40a73.png" alt=""></p>
<p>前面学习了如何对颜色目标进行识别和定位，现在需要把机器人的运动控制加入进来，实现机器人对颜色目标的一个跟随运动。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730962549596-1d2d1689-6ffa-410a-8954-bdd8377b8b39.png" alt=""></p>
<p>机器人正前方的橘色球正好位于画面中的竖直中线上，机器人左前方的红色球，在相机图像中正好位于中线左侧，右前方绿色球正好位于竖直中线右侧，可以看出目标球相对于机器人左右的偏移方向和相机图像中目标球相对于竖直中线的偏移方向是一致的，当相机图像中，目标球位于竖直中线时，机器人刚好正对目标球，所以咱们可以把相机图像中，目标球和竖直中线的横向偏差和机器人的旋转速度挂钩，这样就能驱使机器人旋转，去对准目标球。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730963438372-80040bb1-a588-416e-83c0-7363613246d2.png" alt=""></p>
<p>然后再看看目标球的远近在相机图像中的表现，可以看到远处的蓝色球在相机图像中与画面底部的距离较大，近处的橘色球与画面底部的距离较小，可以发现目标球距离的远近和它在相机图像中的高度有关，所以将目标球的纵坐标和机器人前后运动速度挂钩，就能让机器人不断的靠近目标球，但是如果直接使用这个纵坐标，那么机器人就会一直追，追到目标球处于画面下边界才会停止，这时候目标球再往下移动就会出界丢失了，</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730963679937-ddee9e2e-0c2c-44a4-951b-222452c67678.png" alt=""></p>
<p>所以一般在相机图像中，会给目标球的上下留出余量，这样当目标球上下移动时还能继续追踪，</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730963879442-1809b45a-88ec-4a40-bc82-11520eec23d0.png" alt=""><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730963942576-f47409d3-eabd-4b7b-9ff3-eb6c3c2b6909.png" alt=""></p>
<p>第一次就简单点，直接选相机图像的中点作为对准目标球的位置，只要把目标球的横竖坐标与相机图像的中点做差值，然后和机器人的旋转以及前后运动速度挂钩，就能让机器人始终对准目标球，并和目标球保持特定的距离。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730964154031-893b02e7-f3c0-48f0-82be-3c8e7c2acd75.png" alt=""><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730964239389-2f5419f0-ea70-4ad4-b2f5-95fde3f06d36.png" alt=""></p>
<p>这样目标跟随就实现了。</p>
<p><strong>代码实现：</strong></p>
<p>首先引入头文件，和前面相比多了个速度控制消息包的头文件，然后是OpenCV和STL标准库的命名空间，用于简化代码书写，</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;opencv2/imgproc/imgproc.hpp&gt;
#include &lt;opencv2/highgui/highgui.hpp&gt;
#include &lt;geometry_msgs/Twist.h&gt;   // 速度控制消息包的头文件

using namespace cv;
using namespace std;
</code></pre><p>接下来，定义6个HSV颜色分割阈值变量，</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>static int iLowH = 10;
static int iHighH = 40;

static int iLowS = 90;
static int iHighS = 255;

static int iLowV = 1;
static int iHighV = 255;
</code></pre><p>再定义一个速度控制消息包_vel_cmd_和速度发布对象_vel_pub_，把这两个对象定义在文件开头而不是main（）函数，是为了在mian（）函数和回调函数中都能使用，后面会在main（）函数中对它进行初始化，然后在回调函数用它们来发送速度消息，</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730965333474-a5b179da-e1b4-42f8-a79e-92f4011cc9f6.png" alt=""></p>
<p>下面来编写_<strong>main主函数</strong>_，还是一样的套路，</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>int main(int argc, char **argv)
{
    ros::init(argc, argv, "cv_follow_node");

    ros::NodeHandle nh;
    ros::Subscriber rgb_sub = nh.subscribe("/kinect2/qhd/image_color_rect", 1, Cam_RGB_Callback);
    vel_pub = nh.advertise&lt;geometry_msgs::Twist&gt;("/cmd_vel",30);

    // 生成图像显示和参数调节的窗口
    namedWindow("Threshold", WINDOW_AUTOSIZE);
    // 调用createTrackbar()创建滑杆控件,动态调节参数 （滑杆名称，滑杆隶属窗口标题，阈值变量，
    createTrackbar("LowH", "Threshold", &amp;iLowH, 179);  //Hue (0 - 179)  （0-360）缩小一半--》（0，179）
    createTrackbar("HighH", "Threshold", &amp;iHighH, 179);

    createTrackbar("LowS", "Threshold", &amp;iLowS, 255);  //Saturation (0 - 255)
    createTrackbar("HighS", "Threshold", &amp;iHighS, 255);

    createTrackbar("LowV", "Threshold", &amp;iLowV, 255);  //Value (0 - 255)
    createTrackbar("HighV", "Threshold", &amp;iHighV, 255);

    namedWindow("RGB");
    //namedWindow("HSV");
    namedWindow("Result");

    //ros::spin();
    ros::Rate loop_rate(30);
    while(ros::ok())
    {
        ros::spinOnce();
        loop_rate.sleep();
    }
}
</code></pre><p>接下来编写_<strong>回调函数</strong>_，也是一样的套路，回调函数的开头，先将接收到的消息包里的图像数据从ROS的Image格式转换为OpenCV的Mat格式，暂存在imgOriginal对象里，</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>void Cam_RGB_Callback(const sensor_msgs::Image msg)
{
    cv_bridge::CvImagePtr cv_ptr;
    try
    {
        cv_ptr = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::RGB8);
    }
    catch(cv_bridge::Exception&amp; e)
    {
        ROS_ERROR("cv_bridge exception: %s", e.what());
        return;
    }
    Mat imgOriginal = cv_ptr-&gt;image;

    // ... ...
}
</code></pre><pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>    //将RGB图片转换成HSV
    Mat imgHSV;
    cvtColor(imgOriginal, imgHSV, COLOR_BGR2HSV);
    //在HSV空间做直方图均衡化
    vector&lt;Mat&gt; hsvSplit;
    split(imgHSV, hsvSplit);
    equalizeHist(hsvSplit[2], hsvSplit[2]);
    merge(hsvSplit, imgHSV);

    //使用上面的Hue, Saturation和Value的阈值范围对图像进行二值化
    Mat imgThresholded;
    inRange(imgHSV, Scalar(iLowH, iLowS, iLowV), Scalar(iHighH, iHighS, iHighV), imgThresholded);

    //开操作(去除一些噪点)
    Mat element = getStructuringElement(MORPH_RECT, Size(5,5));
    morphologyEx(imgThresholded, imgThresholded, MORPH_OPEN, element);
    //闭操作（连接一些连通域）
    morphologyEx(imgThresholded, imgThresholded, MORPH_CLOSE, element);

    //遍历二值化后的图像数据
    int nTargetX = 0;
    int nTargetY = 0;
    int nPixCount = 0;
    int nImgWidth = imgThresholded.cols;
    int nImgHeight = imgThresholded.rows;
    int nImgChannels = imgThresholded.channels();
    for (int y = 0; y &lt; nImgHeight; y++)
    {
        for(int x = 0; x &lt; nImgWidth; x++)
        {
            if(imgThresholded.data[y*nImgWidth + x] == 255)
            {
                nTargetX += x;
                nTargetY += y;
                nPixCount ++;
            }
        }
    }

    if(nPixCount &gt; 0)
    {
        nTargetX /= nPixCount;
        nTargetY /= nPixCount;
        printf("颜色质心坐标(%d, %d) 点数 = %d\n",nTargetX, nTargetY, nPixCount);
        //画坐标
        Point line_begin = Point(nTargetX-10, nTargetY);
        Point line_end = Point(nTargetX+10, nTargetY);
        line(imgOriginal,line_begin,line_end,Scalar(255,0,0));

        line_begin.x = nTargetX; line_begin.y = nTargetY-10;
        line_end.x = nTargetX; line_end.y = nTargetY+10;
        line(imgOriginal,line_begin,line_end,Scalar(255,0,0));

        //计算机器人的运动速度
        
    }

</code></pre><p>接下来是主要任务，计算机器人的跟随速度值，</p>
<p><em>画面中点的坐标（nImgWidth/2，nImgHeight/2），目标球的坐标（nTargetX，nTargetY）</em></p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>        //计算机器人的运动速度 
        float fVelFoward = (nImgHeight/2-nTargetY)*0.002;  //移动速度 差值*比例
        float FVelTurn = (nImgWidth/2-nTargetX)*0.003;  //旋转速度 差值*比例
        //将结果赋值到速度消息包里 发送给机器人执行
        vel_cmd.linear.x = fVelFoward;
        vel_cmd.linear.y = 0;
        vel_cmd.linear.z = 0;
        vel_cmd.angular.x = 0;
        vel_cmd.angular.y = 0;
        vel_cmd.angular.z = FVelTurn;   
    }
    else
    {
        printf("目标颜色消失...\n");
        vel_cmd.linear.x = 0;
        vel_cmd.linear.y = 0;
        vel_cmd.linear.z = 0;
        vel_cmd.angular.x = 0;
        vel_cmd.angular.y = 0;
        vel_cmd.angular.z = 0;  
    }
    // 将速度消息包发送出去 控制机器人运动
    vel_pub.publish(vel_cmd);
    printf("机器人运动速度(linear,x= %.2f, angular.z= %.2f)\n", vel_cmd.linear.x, vel_cmd.linear.y, vel_cmd.linear.z);

    //显示处理结果
    imshow("RGB",imgOriginal);
    imshow("Result", imgThresholded);
    cv::waitKey(1);
</code></pre><p><em><strong>添加节点文件编译规则</strong></em></p>
<p>catkin_make编译一下，</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>启动仿真环境 roslaunch wpr_simulation wpb_balls.launch
运行节点代码 rosrun cv_pkg cv_hsv_node 
移动小球 rosrun wpr_simulation ball_random_move
</code></pre><p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730973850155-65a495ed-b75c-4149-81d0-25c9dc2351c8.png" alt=""></p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730973930369-1df13b95-9935-44cf-a30d-b1179e6463b5.png" alt=""></p>
<h2 id="ros-人脸检测的-c-实现">ROS 人脸检测的 C++ 实现 </h2>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730974336626-025f110d-2f0f-4937-9aec-5fa97b2eed27.png" alt=""></p>
<p>人脸检测，也就是从机器人的相机图像中，检测出人脸并标注出他的位置，在OpenCV函数库中，集合了很多图形相关的分类器，可以很容易的将很多经典算法应用到咱们机器人视觉系统中去，比如这次人脸检测使用的就是一种基于Haar特征的级联分类器。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730974625218-3a5a9e35-e852-4eea-b230-5f6871803c80.png" alt=""><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730974911198-d2f26b60-6216-4679-ac88-08885d4b9d26.png" alt=""></p>
<p>所谓的Haar特征，其实指的是一些表示明暗几何关系的模版，其中黑色矩形表示暗的区域，白色矩形表示暗的区域，这些特征模版该怎么使用呢？以人脸检测为例，在做检测时会将上述模版挨个放到目标图像中去进行拉伸和平移，然后进行匹配。比如这个图像中，眼睛这个区域，比下面脸颊这个区域要暗一些，所以当这个x2特征模版在图像中不停的拉伸平移，移到下图位置时，它就匹配到了明暗特征，于是就在图像中找到一个符合x2特征的模版特征，在咱们这个人脸检测任务中，会用到很多的Haar特征模版，一次、、依次按照这个流程在图像进行匹配，每一个特征模版的匹配结果作为一级，于是就得到这样一个多级检测的结构，这就是所谓的级联分类器，只有经过这重重筛选，满足了所有特征的图像，才能认为是一个人脸图像。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1730975377382-d7387922-80e4-4a5e-8b02-41103b5a7868.png" alt=""><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1731052750501-7f532922-15a6-41d7-8124-03f0b43ea6df.png" alt=""><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1731053388242-2c3a2556-3453-44c9-bc10-6672fc624df5.png" alt=""></p>
<p>OpenCV里自带了这个级联分类器，只需要调用这个函数就能实现</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>#include &lt;ros/ros.h&gt;
#include &lt;cv_bridge/cv_bridge.h&gt;
#include &lt;sensor_msgs/image_encodings.h&gt;
#include &lt;opencv2/imgproc/imgproc.hpp&gt;
#include &lt;opencv2/highgui/highgui.hpp&gt;
#include &lt;opencv2/objdetect/objdetect.hpp&gt;  //OpenCV的检测函数头文件

using namespace cv;
using namespace std;
</code></pre><p>定义一个分类器用来检测人脸，定义一个Mat对象用来存储黑白图像，分类器注意基于亮度特征进行检测，输入数据需要时黑白图像，接下来定义一个STL的Vector容器（类似数组），接下来定义一个和这个faces数组配套的迭代器，后面遍历这个数组时会用到，</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>static CascadeClassifier face_cascade;

static Mat frame_gray;
static vector&lt;Rect&gt; faces;
static vector&lt;Rect&gt;::const_iterator face_iter;
</code></pre><p>接下来编写main主函数，</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>int main(int argc, char **argv)
{
    ros::init(argc, argv, "cv_face_detect");
    namedWindow("faces");

    std::string strLoadFile;
    char const* home = getenv("HOME");
    strLoadFile = home;
    strLoadFile += "/catkin_ws";
    strLoadFile += "/src/wpr_simulation/config/haarcascade_frontalface_alt.xml";

    bool res = face_cascade.load(strLoadFile);
    if(res == false)
    {
        ROS_ERROR("fail to load haarcascade_frontalface_alt.xml");
        return 0;
    }
    ros::NodeHandle nh;
    ros::Subscriber rgb_sub = nh.subscribe("/kinect2/qhd/image_color_rect", 1, Cam_RGB_Callback);

    ros::spin();
    return 0;
}
</code></pre><pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>void Cam_RGB_Callback(const sensor_msgs::Image msg)
{
    cv_bridge::CvImagePtr cv_ptr;
    try
    {
        cv_ptr = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::RGB8);
    }
    catch(cv_bridge::Exception&amp; e)
    {
        ROS_ERROR("cv_bridge exception: %s", e.what());
        return;
    }
    Mat imgOriginal = cv_ptr-&gt;image;

    // ... ...
    // 转换成黑白图像
    cvtColor(imgOriginal, frame_gray, CV_BGR2GRAY);
    equalizeHist(frame_gray, frame_gray);

    // 检测人脸
    face_cascade.detectMultiScale(frame_gray, faces, 1.1, 9, 0|CASCADE_SCALE_IMAGE, Size(30, 30));

    // 在彩色原图中标注人脸位置
    if(faces.size() &gt; 0)
    {
        for(face_iter = faces.begin(); face_iter != faces.end(); ++face_iter)
        {
            rectangle(
                imgOriginal,
                Point(face_iter-&gt;x, face_iter-&gt;y),
                Point(face_iter-&gt;x + face_iter-&gt;width, face_iter-&gt;y+ face_iter-&gt;height),
                CV_RGB(255, 0, 255),
                2
            );
        }
    }
    imshow("faces", imgOriginal);
    waitKey(1);
}
</code></pre><p>添加编译规则，</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>add_executable(cv_face_detect src/cv_face_detect.cpp)
add_dependencies(cv_face_detect  ${${PROJECT_NAME}_EXPORTED_TARGETS} ${catkin_EXPORTED_TARGETS})
target_link_libraries(cv_face_detect 
  ${catkin_LIBRARIES} ${OpenCV_LIBS} ${console_bridge_LIBRARIES}
)
</code></pre><p>编译运行，</p>
<pre data-role="codeBlock" data-info="plain" class="language-plain plain"><code>roslaunch wpr_simulation wpr1_single_face.launch
rosrun cv_pkg cv_face_detect
rosrun wpr_simulation keyboard_vel_ctrl   //键盘控制
</code></pre><p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1731314366678-b4ff39b3-73ea-4116-b25e-f1b314f61b42.png" alt=""></p>
<p><img src="https://cdn.nlark.com/yuque/0/2024/png/39216292/1731314344741-14e7bbbb-ad24-4a97-8031-bda95441d23d.png" alt=""></p>

      </div>
      
      
    
    
    
    
    
    
  
    </body></html>